{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1Z-0ywnawS-40hJ18QOq9n6LJoi5Yp5Nw","authorship_tag":"ABX9TyN0TM7OCLFykqaFVI/2gyfV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["세팅"],"metadata":{"id":"DAltqKmWx9Ym"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"k_UtfSifxJHU","executionInfo":{"status":"ok","timestamp":1703031279028,"user_tz":-540,"elapsed":563,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"outputs":[],"source":["import os\n","import cv2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","import numpy as np\n","import shutil\n","\n","# 원본 데이터셋 경로\n","source_dataset_path  = '/content/drive/MyDrive/Python_project/Data/current_dataset'\n","resized_dataset_path = '/content/drive/MyDrive/Python_project/Data/resized_dataset'\n","model_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/model'\n","\n","# 쓰레기 카테고리\n","categories = ['glass','metal','paper','plastic','vinyl']\n","sizes = []\n","\n","# 테스트를 위해 갯수 제한\n","# images_per_category = 300\n","\n","# 이미지 리사이즈 크기 결정\n","resize_width, resize_height = 384, 512"]},{"cell_type":"markdown","source":["리사이즈 이미지 설정"],"metadata":{"id":"AZI3sBs7yC3G"}},{"cell_type":"code","source":["for category in categories:\n","    category_path = os.path.join(source_dataset_path, category)\n","    # 카테고리 폴더 내의 이미지 중 png,jpg,jpeg 필터링\n","    # 앞의 f 필터링된 파일이름\n","    # 뒤의 f 카테고리 폴더의 모든 파일\n","    # f.lower().endswith(('.png', '.jpg', '.jpeg') -> 파일이름을 소문자로 변경하고\n","    # 해당 이름이 '.png', '.jpg', 또는 '.jpeg'로 끝나는지를 검사\n","    image_files = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","    # 각 카테고리별로 지정된 수의 이미지만 처리\n","    for filename in image_files[:]:# images_per_category\n","        file_path = os.path.join(category_path, filename)\n","        # OpenCV를 사용하여 이미지를 로드하고, 이미지의 크기를 sizes 리스트에 추가합니다.\n","        image = cv2.imread(file_path)\n","        if image is not None:\n","            sizes.append(image.shape[:2])  # 이미지의 높이와 너비만 추출"],"metadata":{"id":"9hxHto7-yBdV","executionInfo":{"status":"ok","timestamp":1703031289222,"user_tz":-540,"elapsed":9648,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 이미지 크기 통계 계산\n","if sizes:\n","    heights, widths = zip(*sizes)\n","    avg_height = sum(heights) / len(heights)\n","    avg_width = sum(widths) / len(widths)\n","    min_height = min(heights)\n","    min_width = min(widths)\n","    median_height = sorted(heights)[len(heights) // 2]\n","    median_width = sorted(widths)[len(widths) // 2]\n","else:\n","    avg_height = avg_width = min_height = min_width = median_height = median_width = 0\n","\n","(avg_height, avg_width), (min_height, min_width), (median_height, median_width)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdWx-30NdcVp","executionInfo":{"status":"ok","timestamp":1703031289222,"user_tz":-540,"elapsed":11,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"d64d88aa-4e04-48cf-bf02-12754c4a8650"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((366.48687448728464, 472.9179655455291), (159, 177), (384, 512))"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["이미지 리사이즈"],"metadata":{"id":"cBbrnNCNyQFu"}},{"cell_type":"code","source":["# 카테고리별로 폴더를 순회하며 이미지 처리\n","for category in categories:\n","    source_category_path = os.path.join(source_dataset_path, category)\n","    resized_category_path = os.path.join(resized_dataset_path, category)\n","    os.makedirs(resized_category_path, exist_ok=True)  # 리사이즈된 이미지 저장 폴더 생성\n","    # exist_ok=True 해당 디렉토리에 폴더가 존재해도 오류를 발생시키지 않고 넘어감\n","\n","    # 이미지 파일 처리\n","    # images_per_category\n","    image_files = os.listdir(source_category_path)[:]  # 각 폴더별로 처음 50개의 파일만 가져옴\n","    for filename in image_files:\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            file_path = os.path.join(source_category_path, filename)\n","            image = cv2.imread(file_path)\n","            if image is not None:\n","                resized_image = cv2.resize(image, (resize_width, resize_height))\n","                cv2.imwrite(os.path.join(resized_category_path, filename), resized_image)"],"metadata":{"id":"TwUm9KFgyUaV","executionInfo":{"status":"ok","timestamp":1703031320673,"user_tz":-540,"elapsed":31452,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["데이터 전처리 및 분할"],"metadata":{"id":"8t-WTrnJybcW"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=10,  # 이미지 회전 범위\n","    width_shift_range=0.1,  # 수평 이동 범위\n","    height_shift_range=0.1,  # 수직 이동 범위\n","    shear_range=0.1,  # 전단 변환 범위\n","    zoom_range=0.1,  # 확대/축소 범위\n","    horizontal_flip=True,  # 수평 뒤집기 적용\n","    fill_mode='nearest',\n","    validation_split=0.2  # 데이터셋의 20%를 검증 데이터로 사용\n",")\n","\n","# 참고 : https://tykimos.github.io/2017/06/10/CNN_Data_Augmentation/\n","\n","# 학습 데이터셋 로더 설정\n","train_generator = train_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=32, # 20~30\n","    class_mode='categorical',\n","    subset='training'  # 학습 데이터셋\n",")\n","\n","# 검증 데이터셋 로더 설정\n","validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 검증 데이터셋도 정규화 필요\n","validation_generator = validation_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=32, # 20~30\n","    class_mode='categorical',\n","    subset='validation'  # 검증 데이터셋\n",")"],"metadata":{"id":"lKWGZh3zyZxu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703031320674,"user_tz":-540,"elapsed":10,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"3c63ba1e-4792-4626-d5f5-a5db1c63f0cb"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1952 images belonging to 5 classes.\n","Found 486 images belonging to 5 classes.\n"]}]},{"cell_type":"code","source":["len(train_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hsaJUOzdjjZ","executionInfo":{"status":"ok","timestamp":1703031320674,"user_tz":-540,"elapsed":8,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"2dfde83b-d93c-4611-ce40-564d9f82e1b0"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["len(validation_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRg4RmX3dkoh","executionInfo":{"status":"ok","timestamp":1703031320674,"user_tz":-540,"elapsed":7,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"a4c253ae-8f01-4d80-db5c-f318c3f6484e"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["모델 정의 (Define Network)"],"metadata":{"id":"Hq5PaMWhyhOu"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# 모델 구축\n","model = Sequential([\n","    # 컨볼루션 및 풀링 레이어\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(resize_width, resize_height, 3)),\n","    MaxPooling2D(2, 2),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    # 드롭아웃 추가\n","    Dropout(0.1),\n","    # Flatten 및 Dense 레이어\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(5, activation='softmax')  # 클래스가 5개인 경우\n","])\n","\n","# 모델 요약\n","model.summary()"],"metadata":{"id":"-NLpry-1yjJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703031320674,"user_tz":-540,"elapsed":6,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"4742ffeb-9f84-4fb9-c377-57c42f754178"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 382, 510, 32)      896       \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 191, 255, 32)      0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 189, 253, 64)      18496     \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 94, 126, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 92, 124, 128)      73856     \n","                                                                 \n"," max_pooling2d_6 (MaxPoolin  (None, 46, 62, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 44, 60, 128)       147584    \n","                                                                 \n"," max_pooling2d_7 (MaxPoolin  (None, 22, 30, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 22, 30, 128)       0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 84480)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               10813568  \n","                                                                 \n"," dense_3 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 11055045 (42.17 MB)\n","Trainable params: 11055045 (42.17 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["모델 컴파일 (Compile Network)\n","keras코드 -> tensorflow 코드로 변환"],"metadata":{"id":"oCc6s9LlylRW"}},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","\n","# 모델 컴파일\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"j-Hy-NroynUO","executionInfo":{"status":"ok","timestamp":1703031320674,"user_tz":-540,"elapsed":2,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["모델 학습 (Fit Network)"],"metadata":{"id":"wbMXEZI9y94W"}},{"cell_type":"code","source":["# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=len(train_generator),  # 학습 데이터셋의 이미지 수를 배치 크기로 나눈 값\n","    epochs=70,\n","    validation_data=validation_generator,\n","    validation_steps=len(validation_generator)  # 검증 데이터셋의 이미지 수를 배치 크기로 나눈 값\n",")\n","# 수업 때 배운 걸로 모델 저장하면서 학습\n","model_save_path = os.path.join(model_path, 'my_model.h5')\n","model.save(model_save_path)"],"metadata":{"id":"RslCkucWy4cl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf1ca163-6fbf-449f-9291-90d325241167","executionInfo":{"status":"ok","timestamp":1703037150033,"user_tz":-540,"elapsed":5829361,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/70\n","61/61 [==============================] - 87s 1s/step - loss: 1.4974 - accuracy: 0.3484 - val_loss: 1.2490 - val_accuracy: 0.4733\n","Epoch 2/70\n","61/61 [==============================] - 82s 1s/step - loss: 1.2951 - accuracy: 0.4513 - val_loss: 1.2581 - val_accuracy: 0.4568\n","Epoch 3/70\n","61/61 [==============================] - 82s 1s/step - loss: 1.1899 - accuracy: 0.5231 - val_loss: 1.0514 - val_accuracy: 0.5638\n","Epoch 4/70\n","61/61 [==============================] - 82s 1s/step - loss: 1.0485 - accuracy: 0.5876 - val_loss: 0.9945 - val_accuracy: 0.5700\n","Epoch 5/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.9807 - accuracy: 0.6183 - val_loss: 1.0100 - val_accuracy: 0.5885\n","Epoch 6/70\n","61/61 [==============================] - 81s 1s/step - loss: 0.9552 - accuracy: 0.6301 - val_loss: 1.0727 - val_accuracy: 0.5679\n","Epoch 7/70\n","61/61 [==============================] - 82s 1s/step - loss: 1.0330 - accuracy: 0.5856 - val_loss: 0.9657 - val_accuracy: 0.6420\n","Epoch 8/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.9002 - accuracy: 0.6603 - val_loss: 0.8535 - val_accuracy: 0.6564\n","Epoch 9/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.8004 - accuracy: 0.6911 - val_loss: 0.8891 - val_accuracy: 0.6255\n","Epoch 10/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.8008 - accuracy: 0.7034 - val_loss: 0.8959 - val_accuracy: 0.6481\n","Epoch 11/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.7092 - accuracy: 0.7351 - val_loss: 0.8909 - val_accuracy: 0.6708\n","Epoch 12/70\n","61/61 [==============================] - 85s 1s/step - loss: 0.6943 - accuracy: 0.7413 - val_loss: 0.7635 - val_accuracy: 0.7037\n","Epoch 13/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.6544 - accuracy: 0.7413 - val_loss: 0.8571 - val_accuracy: 0.6728\n","Epoch 14/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.6174 - accuracy: 0.7705 - val_loss: 0.7512 - val_accuracy: 0.7263\n","Epoch 15/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.6315 - accuracy: 0.7551 - val_loss: 0.7780 - val_accuracy: 0.7099\n","Epoch 16/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.6078 - accuracy: 0.7782 - val_loss: 0.7606 - val_accuracy: 0.7099\n","Epoch 17/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.5514 - accuracy: 0.7946 - val_loss: 0.7220 - val_accuracy: 0.7263\n","Epoch 18/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.5369 - accuracy: 0.8028 - val_loss: 0.7889 - val_accuracy: 0.7325\n","Epoch 19/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.5281 - accuracy: 0.8012 - val_loss: 0.6797 - val_accuracy: 0.7531\n","Epoch 20/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.5317 - accuracy: 0.7956 - val_loss: 0.7236 - val_accuracy: 0.7284\n","Epoch 21/70\n","61/61 [==============================] - 85s 1s/step - loss: 0.4953 - accuracy: 0.8176 - val_loss: 1.0290 - val_accuracy: 0.6626\n","Epoch 22/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.4663 - accuracy: 0.8284 - val_loss: 0.8493 - val_accuracy: 0.7222\n","Epoch 23/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.4494 - accuracy: 0.8417 - val_loss: 0.7796 - val_accuracy: 0.7078\n","Epoch 24/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.4350 - accuracy: 0.8320 - val_loss: 0.7226 - val_accuracy: 0.7572\n","Epoch 25/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.4516 - accuracy: 0.8289 - val_loss: 0.7395 - val_accuracy: 0.7551\n","Epoch 26/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.3950 - accuracy: 0.8576 - val_loss: 0.6819 - val_accuracy: 0.7840\n","Epoch 27/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.3809 - accuracy: 0.8581 - val_loss: 0.7109 - val_accuracy: 0.7634\n","Epoch 28/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.3811 - accuracy: 0.8683 - val_loss: 0.6682 - val_accuracy: 0.7860\n","Epoch 29/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.3585 - accuracy: 0.8689 - val_loss: 0.7577 - val_accuracy: 0.7675\n","Epoch 30/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.3333 - accuracy: 0.8770 - val_loss: 0.8044 - val_accuracy: 0.7263\n","Epoch 31/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.3665 - accuracy: 0.8663 - val_loss: 0.7430 - val_accuracy: 0.7716\n","Epoch 32/70\n","61/61 [==============================] - 85s 1s/step - loss: 0.3215 - accuracy: 0.8852 - val_loss: 0.8629 - val_accuracy: 0.7366\n","Epoch 33/70\n","61/61 [==============================] - 85s 1s/step - loss: 0.3152 - accuracy: 0.8873 - val_loss: 0.7673 - val_accuracy: 0.7531\n","Epoch 34/70\n","61/61 [==============================] - 85s 1s/step - loss: 0.3230 - accuracy: 0.8781 - val_loss: 0.7782 - val_accuracy: 0.7695\n","Epoch 35/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.3251 - accuracy: 0.8730 - val_loss: 0.7610 - val_accuracy: 0.7572\n","Epoch 36/70\n","61/61 [==============================] - 85s 1s/step - loss: 0.3874 - accuracy: 0.8555 - val_loss: 0.6704 - val_accuracy: 0.7593\n","Epoch 37/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2780 - accuracy: 0.9042 - val_loss: 0.7472 - val_accuracy: 0.7613\n","Epoch 38/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2583 - accuracy: 0.9088 - val_loss: 0.7465 - val_accuracy: 0.7737\n","Epoch 39/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2649 - accuracy: 0.9057 - val_loss: 0.6868 - val_accuracy: 0.7860\n","Epoch 40/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.2491 - accuracy: 0.9150 - val_loss: 0.7930 - val_accuracy: 0.7695\n","Epoch 41/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2510 - accuracy: 0.9114 - val_loss: 0.8281 - val_accuracy: 0.7881\n","Epoch 42/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.2746 - accuracy: 0.9109 - val_loss: 0.6727 - val_accuracy: 0.8025\n","Epoch 43/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.2860 - accuracy: 0.9042 - val_loss: 0.7482 - val_accuracy: 0.7654\n","Epoch 44/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.2195 - accuracy: 0.9191 - val_loss: 0.7712 - val_accuracy: 0.7716\n","Epoch 45/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.2427 - accuracy: 0.9088 - val_loss: 0.7553 - val_accuracy: 0.7881\n","Epoch 46/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2619 - accuracy: 0.9022 - val_loss: 0.9149 - val_accuracy: 0.7737\n","Epoch 47/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2812 - accuracy: 0.9052 - val_loss: 0.7252 - val_accuracy: 0.7901\n","Epoch 48/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2395 - accuracy: 0.9201 - val_loss: 0.7927 - val_accuracy: 0.7716\n","Epoch 49/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.2171 - accuracy: 0.9242 - val_loss: 0.7795 - val_accuracy: 0.7963\n","Epoch 50/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.2169 - accuracy: 0.9211 - val_loss: 0.7527 - val_accuracy: 0.8066\n","Epoch 51/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.2194 - accuracy: 0.9144 - val_loss: 0.7486 - val_accuracy: 0.8189\n","Epoch 52/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.3599 - accuracy: 0.8740 - val_loss: 0.8321 - val_accuracy: 0.7757\n","Epoch 53/70\n","61/61 [==============================] - 84s 1s/step - loss: 0.2409 - accuracy: 0.9170 - val_loss: 0.6471 - val_accuracy: 0.8128\n","Epoch 54/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.2335 - accuracy: 0.9160 - val_loss: 0.8236 - val_accuracy: 0.7942\n","Epoch 55/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.2112 - accuracy: 0.9293 - val_loss: 0.7945 - val_accuracy: 0.7942\n","Epoch 56/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2305 - accuracy: 0.9170 - val_loss: 0.8176 - val_accuracy: 0.7778\n","Epoch 57/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.1841 - accuracy: 0.9370 - val_loss: 0.7561 - val_accuracy: 0.8107\n","Epoch 58/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2204 - accuracy: 0.9170 - val_loss: 0.7833 - val_accuracy: 0.7984\n","Epoch 59/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.1434 - accuracy: 0.9493 - val_loss: 0.7862 - val_accuracy: 0.7984\n","Epoch 60/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.1318 - accuracy: 0.9529 - val_loss: 0.6598 - val_accuracy: 0.8374\n","Epoch 61/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.1601 - accuracy: 0.9457 - val_loss: 0.7538 - val_accuracy: 0.7984\n","Epoch 62/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.1889 - accuracy: 0.9334 - val_loss: 0.9046 - val_accuracy: 0.7942\n","Epoch 63/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.1745 - accuracy: 0.9406 - val_loss: 0.7569 - val_accuracy: 0.8210\n","Epoch 64/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.2027 - accuracy: 0.9288 - val_loss: 0.7885 - val_accuracy: 0.7984\n","Epoch 65/70\n","61/61 [==============================] - 81s 1s/step - loss: 0.1690 - accuracy: 0.9421 - val_loss: 0.9097 - val_accuracy: 0.7860\n","Epoch 66/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.1669 - accuracy: 0.9467 - val_loss: 0.7681 - val_accuracy: 0.8128\n","Epoch 67/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.1451 - accuracy: 0.9518 - val_loss: 0.8307 - val_accuracy: 0.8148\n","Epoch 68/70\n","61/61 [==============================] - 83s 1s/step - loss: 0.1044 - accuracy: 0.9631 - val_loss: 0.9190 - val_accuracy: 0.8025\n","Epoch 69/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.1655 - accuracy: 0.9462 - val_loss: 0.9136 - val_accuracy: 0.8128\n","Epoch 70/70\n","61/61 [==============================] - 82s 1s/step - loss: 0.1833 - accuracy: 0.9375 - val_loss: 0.9977 - val_accuracy: 0.7881\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"markdown","source":["모델 평가 (Evaluate Network)"],"metadata":{"id":"36RJ2UHGzEwW"}},{"cell_type":"code","source":["# 모델 평가\n","validation_loss, validation_accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Loss: {validation_loss}\")\n","print(f\"Validation Accuracy: {validation_accuracy}\")"],"metadata":{"id":"jtOH-zQbzGsl","executionInfo":{"status":"ok","timestamp":1703037153898,"user_tz":-540,"elapsed":3867,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"36c4d617-420f-4bd0-d443-e1fe7522184e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 4s 212ms/step - loss: 0.9977 - accuracy: 0.7881\n","Validation Loss: 0.9977259635925293\n","Validation Accuracy: 0.7880658507347107\n"]}]},{"cell_type":"markdown","source":["예측 수행 (Make Predictions): 쓰레기 이미지를 넣어 쓰레기의 종류를 분류"],"metadata":{"id":"nwKXmm4OzMd-"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import os\n","\n","# 이미지를 불러오고 전처리하는 함수\n","def load_and_preprocess_image(image_path):\n","    img = image.load_img(image_path, target_size=(resize_width, resize_height))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)  # 모델의 예상 입력 형태에 맞게 차원 추가\n","    img_array /= 255.0  # 이미지 정규화\n","    return img_array\n","\n","# 테스트 이미지 폴더 경로\n","test_images_path = '/content/drive/MyDrive/Python_project/Data/img'\n","\n","# 테스트 이미지 파일 목록 가져오기\n","test_image_files = [os.path.join(test_images_path, f) for f in os.listdir(test_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","# 각 이미지에 대해 예측 수행\n","for image_file in test_image_files:\n","    img_array = load_and_preprocess_image(image_file)\n","    predictions = model.predict(img_array)\n","    predicted_class_index = np.argmax(predictions[0])\n","    predicted_class_name = categories[predicted_class_index]\n","    print(f\"Image: {image_file}, Predicted class: {predicted_class_name}\")\n"],"metadata":{"id":"KTO49i2qzNx2","executionInfo":{"status":"ok","timestamp":1703037167030,"user_tz":-540,"elapsed":13134,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"277861a6-8bb4-44c4-9437-2b3683e5bce1"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 496ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/metal28.jpg, Predicted class: metal\n","1/1 [==============================] - 0s 18ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/metal19.jpg, Predicted class: metal\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/glass26.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/metal1.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 21ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/metal10.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/glass18.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 18ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/glass10.jpg, Predicted class: vinyl\n","1/1 [==============================] - 0s 18ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/glass1.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/glass34.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/paper40.jpg, Predicted class: paper\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/paper1.jpg, Predicted class: paper\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/paper22.jpg, Predicted class: paper\n","1/1 [==============================] - 0s 18ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/paper31.jpg, Predicted class: paper\n","1/1 [==============================] - 0s 18ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/plastic28.jpg, Predicted class: plastic\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/plastic10.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/plastic37.jpg, Predicted class: plastic\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/plastic19.jpg, Predicted class: plastic\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/plastic1.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/metal37.jpg, Predicted class: metal\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/paper13.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/trash108.jpg, Predicted class: vinyl\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/trash71.jpg, Predicted class: vinyl\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/trash9.jpg, Predicted class: vinyl\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/00004033.jpg, Predicted class: vinyl\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/00004023.jpg, Predicted class: vinyl\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/Python_project/Data/img/00004006.jpg, Predicted class: vinyl\n"]}]},{"cell_type":"code","source":["import os\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 이미지를 불러오고 전처리하는 함수\n","def load_and_preprocess_image(image_path):\n","    img = image.load_img(image_path, target_size=(resize_width, resize_height))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)  # 모델의 예상 입력 형태에 맞게 차원 추가\n","    img_array /= 255.0  # 이미지 정규화\n","    return img_array\n","\n","# 디렉토리 이름에서 레이블 추출\n","def extract_label_from_directory(file_path):\n","    return os.path.basename(os.path.dirname(file_path))\n","\n","# 테스트 이미지 폴더 경로\n","test_images_path = '/content/drive/MyDrive/Python_project/Data/img'\n","\n","# 테스트 이미지 파일 목록 가져오기\n","test_image_files = [os.path.join(test_images_path, f) for f in os.listdir(test_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","# 각 이미지에 대해 예측 수행 및 시각화\n","for image_file in test_image_files:\n","    true_label = extract_label_from_directory(image_file)\n","    img_array = load_and_preprocess_image(image_file)\n","    predictions = model.predict(img_array)\n","    predicted_class_index = np.argmax(predictions[0])\n","    predicted_class_name = categories[predicted_class_index]\n","\n","    # 시각화\n","    img = plt.imread(image_file)\n","    plt.imshow(img)\n","    plt.title(f\"Predicted: {predicted_class_name}\")\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"cgDwQbJ3xP5A","executionInfo":{"status":"ok","timestamp":1703037179578,"user_tz":-540,"elapsed":12551,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1P-9AcAO4mdnkRGYAKM-vxzkeWQTZoyQZ"},"outputId":"947d9e4d-9966-4105-82e5-e9b28dc58113"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import os\n","import re\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# 이미지를 불러오고 전처리하는 함수\n","def load_and_preprocess_image(img_path):\n","    img = image.load_img(img_path, target_size=(resize_width, resize_height))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0) / 255.0\n","    return img_array\n","\n","# 파일 이름에서 레이블 추출\n","def get_label_from_filename(file_name):\n","    if re.match(r'glass\\d+', file_name):\n","        return 'glass'\n","    elif re.match(r'metal\\d+', file_name):\n","        return 'metal'\n","    elif re.match(r'paper\\d+', file_name):\n","        return 'paper'\n","    elif re.match(r'plastic\\d+', file_name):\n","        return 'plastic'\n","    elif re.match(r'\\d+', file_name):  # 숫자로만 이루어진 파일 이름 처리\n","        return 'vinyl'\n","    elif re.match(r'trach\\d+', file_name):  # 'trach'로 시작하는 파일 이름 처리\n","        return 'vinyl'\n","    else:\n","        return 'unknown'  # 알려지지 않은 패턴 처리\n","\n","# 모델 예측 및 정확도 계산\n","def evaluate_model_accuracy(model, base_path, categories):\n","    correct_predictions = 0\n","    total_images = 0\n","\n","    # base_path 폴더 내의 모든 파일을 검색\n","    for file_name in os.listdir(base_path):\n","        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            # 레이블 추출 및 이미지 전처리\n","            true_label = get_label_from_filename(file_name)\n","            if true_label != 'unknown':  # 알 수 없는 레이블을 제외\n","                img_path = os.path.join(base_path, file_name)\n","                img_array = load_and_preprocess_image(img_path)\n","\n","                # 예측 실행\n","                prediction = model.predict(img_array)\n","                predicted_label_index = np.argmax(prediction[0])\n","                predicted_label = categories[predicted_label_index]\n","\n","                # 예측 및 실제 레이블 출력\n","                print(f\"Actual: {true_label}, Predicted: {predicted_label}\")\n","\n","                # 예측 정확도 업데이트\n","                if predicted_label == true_label:\n","                    correct_predictions += 1\n","                total_images += 1\n","\n","    # 정확도 계산 및 출력\n","    accuracy = correct_predictions / total_images if total_images > 0 else 0\n","    return accuracy\n","\n","# 모델 정확도 평가\n","base_path = '/content/drive/MyDrive/Python_project/Data/img'\n","categories = ['glass', 'metal', 'paper', 'plastic', 'vinyl']  # 모델이 예측하는 클래스 목록\n","accuracy = evaluate_model_accuracy(model, base_path, categories)\n","print(\"\\n\")\n","print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"id":"RWHhfdJsyQxo","executionInfo":{"status":"ok","timestamp":1703037180076,"user_tz":-540,"elapsed":505,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"288a2cc5-7223-4d3a-bde8-fd4a4595afc0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","Actual: metal, Predicted: metal\n","1/1 [==============================] - 0s 18ms/step\n","Actual: metal, Predicted: metal\n","1/1 [==============================] - 0s 18ms/step\n","Actual: glass, Predicted: glass\n","1/1 [==============================] - 0s 18ms/step\n","Actual: metal, Predicted: glass\n","1/1 [==============================] - 0s 18ms/step\n","Actual: metal, Predicted: glass\n","1/1 [==============================] - 0s 18ms/step\n","Actual: glass, Predicted: glass\n","1/1 [==============================] - 0s 18ms/step\n","Actual: glass, Predicted: vinyl\n","1/1 [==============================] - 0s 18ms/step\n","Actual: glass, Predicted: glass\n","1/1 [==============================] - 0s 17ms/step\n","Actual: glass, Predicted: glass\n","1/1 [==============================] - 0s 17ms/step\n","Actual: paper, Predicted: paper\n","1/1 [==============================] - 0s 18ms/step\n","Actual: paper, Predicted: paper\n","1/1 [==============================] - 0s 18ms/step\n","Actual: paper, Predicted: paper\n","1/1 [==============================] - 0s 18ms/step\n","Actual: paper, Predicted: paper\n","1/1 [==============================] - 0s 18ms/step\n","Actual: plastic, Predicted: plastic\n","1/1 [==============================] - 0s 18ms/step\n","Actual: plastic, Predicted: glass\n","1/1 [==============================] - 0s 18ms/step\n","Actual: plastic, Predicted: plastic\n","1/1 [==============================] - 0s 19ms/step\n","Actual: plastic, Predicted: plastic\n","1/1 [==============================] - 0s 19ms/step\n","Actual: plastic, Predicted: glass\n","1/1 [==============================] - 0s 18ms/step\n","Actual: metal, Predicted: metal\n","1/1 [==============================] - 0s 18ms/step\n","Actual: paper, Predicted: glass\n","1/1 [==============================] - 0s 19ms/step\n","Actual: vinyl, Predicted: vinyl\n","1/1 [==============================] - 0s 19ms/step\n","Actual: vinyl, Predicted: vinyl\n","1/1 [==============================] - 0s 20ms/step\n","Actual: vinyl, Predicted: vinyl\n","\n","\n","Model Accuracy: 73.91%\n"]}]}]}