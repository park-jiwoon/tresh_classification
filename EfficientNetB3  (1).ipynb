{"cells":[{"cell_type":"markdown","metadata":{"id":"xuhJ1-ibZJVf"},"source":["# 모델"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1705373258951,"user":{"displayName":"JW P","userId":"05164750983755444081"},"user_tz":-540},"id":"A0jSlqINPBTb"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705373259609,"user":{"displayName":"JW P","userId":"05164750983755444081"},"user_tz":-540},"id":"lM82Q81EKYRG"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705373259609,"user":{"displayName":"JW P","userId":"05164750983755444081"},"user_tz":-540},"id":"BH3KeQ9Wc_I2"},"outputs":[],"source":["# 라이브러리\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import random\n","from cv2 import resize\n","from glob import glob\n","from tensorflow.keras.models import load_model\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications.efficientnet import EfficientNetB3\n","from tensorflow.keras.applications.efficientnet import preprocess_input\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8575,"status":"ok","timestamp":1705373258518,"user":{"displayName":"JW P","userId":"05164750983755444081"},"user_tz":-540},"id":"8kCmRHQSYY-x","outputId":"cd55db25-e661-4663-8946-23da0a5eb9c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1218 files belonging to 3 classes.\n","Using 975 files for training.\n","Found 1218 files belonging to 3 classes.\n","Using 243 files for validation.\n"]}],"source":["# 이미지 데이터셋 로드 및 전처리\n","\n","img_height = 244\n","img_width = 244\n","num_classes = 10\n","\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","  '/content/drive/MyDrive/1주일 프로젝트/Data_set',\n","  validation_split=0.2,\n","  subset='training',\n","  image_size=(img_height, img_width),\n","  batch_size=32,\n","  seed=42,\n","  shuffle=True)\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  '/content/drive/MyDrive/1주일 프로젝트/Data_set',\n","  validation_split=0.2,\n","  subset='validation',\n","  image_size=(img_height, img_width),\n","  batch_size=32,\n","  seed=42,\n","  shuffle=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705373259610,"user":{"displayName":"JW P","userId":"05164750983755444081"},"user_tz":-540},"id":"NHuV5iYsc-5f","outputId":"5d971a79-d81b-4c6a-a878-62152d315c15"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Cleaning', 'Exchange', 'Normal']\n"]},{"data":{"text/plain":["\u003c_PrefetchDataset element_spec=(TensorSpec(shape=(None, 244, 244, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\u003e"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# 훈련 데이터셋 클래스 이름 확인 (Auto)\n","\n","class_names = train_ds.class_names\n","print(class_names)\n","train_ds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1DiEIPQuRnr0acZGxlEdOUILnWHec8IyP"},"id":"8RIX-rsMdQc2","outputId":"c4d77923-e21e-4084-b2b8-bd4bca5b224c"},"outputs":[],"source":["# 훈련 데이터셋 샘플 이미지\n","\n","plt.figure(figsize=(15, 15))\n","for images, labels in train_ds.take(1):\n","    for i in range(25):\n","        ax = plt.subplot(5, 5, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.title(class_names[labels[i]])\n","        plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kh-C45prda7O"},"outputs":[],"source":["#  모델 로드 및 설정 (가중치 유지)\n","\n","base_model = EfficientNetB3(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(img_height, img_width, 3)\n",")\n","base_model.trainable = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1GuWTSRdcGG"},"outputs":[],"source":["# 커스텀 모델 아키텍처 정의\n","inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n","x = preprocess_input(inputs)\n","x = base_model(x, training=False)\n","x = GlobalAveragePooling2D()(x)\n","x = Dropout(0.3)(x)\n","outputs = Dense(num_classes, activation='softmax')(x)\n","model = tf.keras.Model(inputs, outputs)\n","\n","# 모델 컴파일\n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 요약\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjZ0W2kEeC8e"},"outputs":[],"source":["# 모델 컴파일 및 학습 설정\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcbxXkq9eD9G"},"outputs":[],"source":["# 모델 훈련\n","\n","epoch = 15\n","model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n","    callbacks = [\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor=\"val_loss\",\n","            min_delta=0.01,\n","            patience=3,\n","            verbose=1,\n","            restore_best_weights=True\n","        )\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fdYbHTieFOn"},"outputs":[],"source":["# 모델의 미세 조정 설정 및 요약\n","\n","base_model.trainable = True\n","for layer in base_model.layers[:14]:\n","    layer.trainable = False\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qiXrKHsieIef"},"outputs":[],"source":["# 미세 조정을 위한 모델 재컴파일\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yTSfbz_eaQX"},"outputs":[],"source":["# 모델 훈련 (미세 조정)\n","epoch = 15\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=epoch,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor=\"val_loss\",\n","            min_delta=0.01,\n","            patience=3,\n","            verbose=1,\n","        )\n","    ]\n",")\n","\n","# 훈련이 끝난 후 모델 저장\n","model.save('/content/drive/MyDrive/1주일 프로젝트/PARK/EfficientNetB3_model/EfficientNetB3_model.h5')"]},{"cell_type":"markdown","metadata":{"id":"aEWJhcuQZCqQ"},"source":["# 시각화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvEcjlgjebkP"},"outputs":[],"source":["# 훈련 및 검증 데이터에 대한 정확도와 손실\n","\n","get_ac = history.history['accuracy']\n","get_los = history.history['loss']\n","val_acc = history.history['val_accuracy']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(get_ac))\n","plt.plot(epochs, get_ac, 'g', label='Accuracy of Training data')\n","plt.plot(epochs, get_los, 'r', label='Loss of Training data')\n","plt.title('Training data accuracy and loss')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","plt.plot(epochs, get_ac, 'g', label='Accuracy of Training Data')\n","plt.plot(epochs, val_acc, 'r', label='Accuracy of Validation Data')\n","plt.title('Training and Validation Accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","plt.plot(epochs, get_los, 'g', label='Loss of Training Data')\n","plt.plot(epochs, val_loss, 'r', label='Loss of Validation Data')\n","plt.title('Training and Validation Loss')\n","plt.legend(loc=0)\n","plt.figure()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1aPmGLkG7AO-uYwOIyuY9Jp2Dl6XJv6bT"},"id":"B6CmPMZ_ednW","outputId":"d229e1ed-c9f4-4bca-b57c-0aafc098260b"},"outputs":[],"source":["# 모델 평가 및 예측 결과 시각화\n","\n","loss, accuracy = model.evaluate(val_ds)\n","\n","plt.figure(figsize=(20, 20))\n","for images, labels in val_ds.take(1):\n","    for i in range(16):\n","        ax = plt.subplot(4, 4, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        predictions = model.predict(tf.expand_dims(images[i], 0))\n","        score = tf.nn.softmax(predictions[0])\n","        if(class_names[labels[i]]==class_names[np.argmax(score)]):\n","            plt.title(\"Actual: \"+class_names[labels[i]])\n","            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)],fontdict={'color':'green'})\n","\n","        else:\n","            plt.title(\"Actual: \"+class_names[labels[i]])\n","            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)],fontdict={'color':'red'})\n","        plt.gca().axes.yaxis.set_ticklabels([])\n","        plt.gca().axes.xaxis.set_ticklabels([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"C_qlSkGXY0tP"},"source":["# 저장된 모델 로드 후 검증"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mH5eutsEMt9p"},"outputs":[],"source":["# 저장된 모델 불러오기\n","loaded_model = load_model('/content/drive/MyDrive/1주일 프로젝트/PARK/EfficientNetB3_model/EfficientNetB3_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dy6NNA3OPOCT"},"outputs":[],"source":["# 원본 모델로 검증 데이터셋 평가\n","loss, accuracy = loaded_model.evaluate(val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"12GFjf_uzMVn0kxpA2ovCPucLxkASzyc-"},"id":"nQRwYu09PmkJ","outputId":"c9a0acfc-a8e7-4208-87bb-9d72a3aa3ff1"},"outputs":[],"source":["# 저장된 최종 모델 시각화\n","\n","plt.figure(figsize=(20, 20))\n","for images, labels in val_ds.take(1):\n","    for i in range(16):\n","        ax = plt.subplot(4, 4, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        # 저장된 모델로 예측 수행\n","        predictions = loaded_model.predict(tf.expand_dims(images[i], 0))\n","        score = tf.nn.softmax(predictions[0])\n","        if(class_names[labels[i]] == class_names[np.argmax(score)]):\n","            plt.title(\"Actual: \" + class_names[labels[i]])\n","            plt.ylabel(\"Predicted: \" + class_names[np.argmax(score)], fontdict={'color': 'green'})\n","        else:\n","            plt.title(\"Actual: \" + class_names[labels[i]])\n","            plt.ylabel(\"Predicted: \" + class_names[np.argmax(score)], fontdict={'color': 'red'})\n","        plt.gca().axes.yaxis.set_ticklabels([])\n","        plt.gca().axes.xaxis.set_ticklabels([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XlsV_LE5YuhB"},"source":["# 실제 Test 진행"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"N51IMwfHaXEJ"},"outputs":[],"source":["model_path = '/content/drive/MyDrive/1주일 프로젝트/PARK/EfficientNetB3_model/EfficientNetB3_model.h5'\n","model = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"G-c1nNF_dwZA"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Cleaning', 'Exchange', 'Normal']\n"]},{"ename":"AttributeError","evalue":"'function' object has no attribute 'glob'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-25-6d0bb8921e40\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 16\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_formats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 17\u001b[0;31m     \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/**/*.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'glob'"]}],"source":["import os\n","from tensorflow.keras.preprocessing import image\n","\n","# 테스트 이미지가 있는 경로\n","test_images_directory = '/content/drive/MyDrive/1주일 프로젝트/Test_set'\n","\n","# 훈련 데이터셋 클래스 이름 확인\n","class_names = train_ds.class_names\n","print(class_names)\n","\n","# 모든 이미지 파일 확장자\n","image_formats = ['jpg', 'jpeg', 'png', 'bmp', 'tiff']\n","\n","# 모든 하위 디렉토리를 탐색하여 이미지 파일 찾기\n","test_images = []\n","for fmt in image_formats:\n","    test_images.extend(glob.glob(test_images_directory + '/**/*.' + fmt, recursive=True))\n","\n","plt.figure(figsize=(20, 20))\n","\n","# 첫 16개 이미지에 대해 예측 수행\n","for i in range(9):\n","    img_path = test_images[i]\n","    img = image.load_img(img_path, target_size=(244, 244))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","\n","    images = np.vstack([x])\n","    classes = model.predict(images, batch_size=10)\n","\n","    # 예측 결과 시각화\n","    ax = plt.subplot(4, 4, i + 1)\n","    plt.imshow(img)\n","    plt.title(\"Actual: \" + os.path.basename(os.path.dirname(img_path)))\n","    plt.ylabel(\"Predicted: \" + class_names[np.argmax(classes)], fontdict={'color': 'green' if class_names[np.argmax(classes)] in os.path.basename(os.path.dirname(img_path)) else 'red'})\n","    plt.gca().axes.yaxis.set_ticklabels([])\n","    plt.gca().axes.xaxis.set_ticklabels([])\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","provenance":[{"file_id":"12SQ3dGojFAPgT7MfjTQ51o0BWnmPiYSt","timestamp":1705306778216}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}