{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["ImageDataGenerator\n","- 성능을 올리면서 과적합 방지\n","- 파이프라인\n","- 전처리\n","- 이미지의 다양성\n","- https://techblog-history-younghunjo1.tistory.com/252"],"metadata":{"id":"XULRfVzLahpw"}},{"cell_type":"markdown","source":["- 정규화 - 특징을 더 잘 추출하기 위해\n","- 범주화 - 이미지를 더 잘 분류하기 위해"],"metadata":{"id":"JLU6M3tRk5q6"}},{"cell_type":"code","source":["# 디폴트 batch_size = 32\n","# x_train / 32\n","# 90번\n","# 이미지 장수 = step_per_epoch = 2 * batch_size"],"metadata":{"id":"wHGCVCjAlHUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # 재실행을 위해 필요한 라이브러리를 다시 가져옵니다.\n","# import os\n","\n","# # 원본 데이터셋 경로\n","# source_dataset_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/current_dataset'\n","\n","# # 'trash' 카테고리에 해당하는 경로 설정\n","# trash_category_path = os.path.join(source_dataset_path, 'trash')\n","\n","# # 'trash' 카테고리 폴더 내의 이미지 파일 수를 확인합니다.\n","# if os.path.exists(trash_category_path):\n","#     trash_image_files = [f for f in os.listdir(trash_category_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","#     trash_image_count = len(trash_image_files)\n","# else:\n","#     trash_image_count = 0\n","\n","# trash_image_count"],"metadata":{"id":"WD648g3MpOkX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 세팅"],"metadata":{"id":"JsZZpPgzgzG_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UjyJxqdpRQ7B"},"outputs":[],"source":["import os\n","import cv2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","import numpy as np\n","import shutil\n","\n","# 원본 데이터셋 경로\n","source_dataset_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/current_dataset'\n","resized_dataset_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/resized_dataset'\n","model_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/model'\n","\n","\n","# 쓰레기 카테고리\n","categories = ['metal', 'paper', 'plastic', 'trash', 'cardboard', 'glass']\n","sizes = []\n","\n","# 테스트를 위해 갯수 제한\n","images_per_category = 50\n","\n","# 이미지 리사이즈 크기 결정\n","resize_width, resize_height = 384, 512"]},{"cell_type":"markdown","source":["# 리사이즈 이미지 설정"],"metadata":{"id":"i53pnXn8ZdxO"}},{"cell_type":"code","source":["for category in categories:\n","    category_path = os.path.join(source_dataset_path, category)\n","    # 카테고리 폴더 내의 이미지 중 png,jpg,jpeg 필터링\n","    # 앞의 f 필터링된 파일이름\n","    # 뒤의 f 카테고리 폴더의 모든 파일\n","    # f.lower().endswith(('.png', '.jpg', '.jpeg') -> 파일이름을 소문자로 변경하고\n","    # 해당 이름이 '.png', '.jpg', 또는 '.jpeg'로 끝나는지를 검사\n","    image_files = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","    # 각 카테고리별로 지정된 수의 이미지만 처리\n","    for filename in image_files[:images_per_category]:\n","        file_path = os.path.join(category_path, filename)\n","        # OpenCV를 사용하여 이미지를 로드하고, 이미지의 크기를 sizes 리스트에 추가합니다.\n","        image = cv2.imread(file_path)\n","        if image is not None:\n","            sizes.append(image.shape[:2])  # 이미지의 높이와 너비만 추출"],"metadata":{"id":"sWnecN3vZDJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sizes"],"metadata":{"id":"41YnTa4UCqjW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 크기 통계 계산\n","if sizes:\n","    heights, widths = zip(*sizes)\n","    avg_height = sum(heights) / len(heights)\n","    avg_width = sum(widths) / len(widths)\n","    min_height = min(heights)\n","    min_width = min(widths)\n","    median_height = sorted(heights)[len(heights) // 2]\n","    median_width = sorted(widths)[len(widths) // 2]\n","else:\n","    avg_height = avg_width = min_height = min_width = median_height = median_width = 0\n","\n","(avg_height, avg_width), (min_height, min_width), (median_height, median_width)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARePlGtxBjK3","executionInfo":{"status":"ok","timestamp":1702901759829,"user_tz":-540,"elapsed":2,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"01768ead-48c9-40e7-c603-e0f922386c99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((384.0, 512.0), (384, 512), (384, 512))"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["# 이미지 리사이즈"],"metadata":{"id":"svuomc9uZ2lW"}},{"cell_type":"code","source":["# 카테고리별로 폴더를 순회하며 이미지 처리\n","for category in categories:\n","    source_category_path = os.path.join(source_dataset_path, category)\n","    resized_category_path = os.path.join(resized_dataset_path, category)\n","    os.makedirs(resized_category_path, exist_ok=True)  # 리사이즈된 이미지 저장 폴더 생성\n","    # exist_ok=True 해당 디렉토리에 폴더가 존재해도 오류를 발생시키지 않고 넘어감\n","\n","    # 이미지 파일 처리\n","    image_files = os.listdir(source_category_path)[:images_per_category]  # 각 폴더별로 처음 50개의 파일만 가져옴\n","    for filename in image_files:\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            file_path = os.path.join(source_category_path, filename)\n","            image = cv2.imread(file_path)\n","            if image is not None:\n","                resized_image = cv2.resize(image, (resize_width, resize_height))\n","                cv2.imwrite(os.path.join(resized_category_path, filename), resized_image)"],"metadata":{"id":"O9gCPBvTZ3wG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 전처리 및 분할"],"metadata":{"id":"hYlTcNr8gfEH"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,  # 회전 범위를 줄임\n","    width_shift_range=0.1,  # 이동 범위를 줄임\n","    height_shift_range=0.1,  # 이동 범위를 줄임\n","    shear_range=0.1,  # 전단 변환 범위를 줄임\n","    zoom_range=0.1,  # 확대/축소 범위를 줄임\n","    horizontal_flip=True, # 무작위 수평 뒤집기\n","    fill_mode='nearest', # 회전 또는 너비/높이 이동으로 인해 새롭게 생성해야 할 픽셀을 채우는 방식\n","    validation_split=0.2  # 데이터셋의 20%를 검증 데이터로 사용\n",")\n","\n","# 참고 : https://tykimos.github.io/2017/06/10/CNN_Data_Augmentation/\n","\n","# 학습 데이터셋 로더 설정\n","train_generator = train_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training'  # 학습 데이터셋\n",")\n","\n","# 검증 데이터셋 로더 설정\n","validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 검증 데이터셋도 정규화 필요\n","validation_generator = validation_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation'  # 검증 데이터셋\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1M-nePk_gfp-","executionInfo":{"status":"ok","timestamp":1702901769209,"user_tz":-540,"elapsed":304,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"1bf8a416-c29d-4990-dab9-4ff468a58e2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 240 images belonging to 6 classes.\n","Found 60 images belonging to 6 classes.\n"]}]},{"cell_type":"code","source":["len(train_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7pOnjFGn_NC","executionInfo":{"status":"ok","timestamp":1702901769905,"user_tz":-540,"elapsed":276,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"19ff6cf9-3233-4b1c-e78c-c80eb7749a4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["len(validation_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXKPV3TSoDTR","executionInfo":{"status":"ok","timestamp":1702901769905,"user_tz":-540,"elapsed":2,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"70a487d9-76e9-471e-fd2c-c4dc44872a4a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["# 모델 정의 (Define Network)"],"metadata":{"id":"ij8AEWuKklAH"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","\n","# 모델 구축\n","model = Sequential([\n","    # 첫 번째 컨볼루션 레이어\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(resize_width, resize_height, 3)),\n","    MaxPooling2D(2, 2),\n","    # 두 번째 컨볼루션 레이어\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    # 세 번째 컨볼루션 레이어\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    # 네 번째 컨볼루션 레이어\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    # Flatten 레이어로 차원 축소\n","    Flatten(),\n","    # 완전 연결 레이어\n","    Dense(128, activation='relu'),  # 예: 128 뉴런으로 변경\n","    # 출력 레이어\n","    Dense(6, activation='softmax')  # 클래스가 6개이므로 뉴런 수를 6개로 설정\n","])\n","\n","# 모델 요약\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wovev7oXkXYX","executionInfo":{"status":"ok","timestamp":1702901777524,"user_tz":-540,"elapsed":336,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"13a756d7-d5c4-44a3-d358-4700d4330947"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 382, 510, 32)      896       \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 191, 255, 32)      0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 189, 253, 64)      18496     \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 94, 126, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 92, 124, 128)      73856     \n","                                                                 \n"," max_pooling2d_6 (MaxPoolin  (None, 46, 62, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 44, 60, 128)       147584    \n","                                                                 \n"," max_pooling2d_7 (MaxPoolin  (None, 22, 30, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_1 (Flatten)         (None, 84480)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               10813568  \n","                                                                 \n"," dense_3 (Dense)             (None, 6)                 774       \n","                                                                 \n","=================================================================\n","Total params: 11055174 (42.17 MB)\n","Trainable params: 11055174 (42.17 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# 모델 컴파일 (Compile Network)\n","- keras코드 -> tensorflow 코드로 변환"],"metadata":{"id":"EAfqg7O5lHgW"}},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","\n","# 모델 컴파일\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"-r2E_EQ6lDw_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 학습 (Fit Network)"],"metadata":{"id":"3TCMcrW4lrZ5"}},{"cell_type":"code","source":["# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=len(train_generator),  # 학습 데이터셋의 이미지 수를 배치 크기로 나눈 값\n","    epochs=20,\n","    validation_data=validation_generator,\n","    validation_steps=len(validation_generator)  # 검증 데이터셋의 이미지 수를 배치 크기로 나눈 값\n",")\n","# 수업 때 배운 걸로 모델 저장하면서 학습\n","model_save_path = os.path.join(model_path, 'my_model.h5')\n","model.save(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Odo-wmoLlrun","executionInfo":{"status":"ok","timestamp":1702901997589,"user_tz":-540,"elapsed":209485,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"ce0a1065-0283-4ec0-dadc-d567f7d45e8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","8/8 [==============================] - 12s 1s/step - loss: 2.1000 - accuracy: 0.1542 - val_loss: 1.7904 - val_accuracy: 0.1833\n","Epoch 2/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.7687 - accuracy: 0.2625 - val_loss: 1.7033 - val_accuracy: 0.3000\n","Epoch 3/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.7159 - accuracy: 0.2500 - val_loss: 1.7232 - val_accuracy: 0.2500\n","Epoch 4/20\n","8/8 [==============================] - 11s 1s/step - loss: 1.7003 - accuracy: 0.2875 - val_loss: 1.6670 - val_accuracy: 0.3167\n","Epoch 5/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.6416 - accuracy: 0.2708 - val_loss: 1.6459 - val_accuracy: 0.3167\n","Epoch 6/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.5357 - accuracy: 0.3833 - val_loss: 1.5975 - val_accuracy: 0.4000\n","Epoch 7/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.4849 - accuracy: 0.3708 - val_loss: 1.4300 - val_accuracy: 0.3500\n","Epoch 8/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.4368 - accuracy: 0.4292 - val_loss: 1.4389 - val_accuracy: 0.3500\n","Epoch 9/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.5587 - accuracy: 0.3583 - val_loss: 1.5117 - val_accuracy: 0.3500\n","Epoch 10/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.5220 - accuracy: 0.4000 - val_loss: 1.4239 - val_accuracy: 0.4000\n","Epoch 11/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.4846 - accuracy: 0.3792 - val_loss: 1.4480 - val_accuracy: 0.4667\n","Epoch 12/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.3649 - accuracy: 0.4875 - val_loss: 1.4354 - val_accuracy: 0.4500\n","Epoch 13/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.2449 - accuracy: 0.4583 - val_loss: 1.4642 - val_accuracy: 0.4667\n","Epoch 14/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.2656 - accuracy: 0.5000 - val_loss: 1.2975 - val_accuracy: 0.5167\n","Epoch 15/20\n","8/8 [==============================] - 11s 1s/step - loss: 1.2128 - accuracy: 0.5500 - val_loss: 1.2588 - val_accuracy: 0.5167\n","Epoch 16/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.1551 - accuracy: 0.5292 - val_loss: 1.5437 - val_accuracy: 0.4500\n","Epoch 17/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.2907 - accuracy: 0.4875 - val_loss: 1.3040 - val_accuracy: 0.5000\n","Epoch 18/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.1914 - accuracy: 0.4917 - val_loss: 1.3069 - val_accuracy: 0.4500\n","Epoch 19/20\n","8/8 [==============================] - 10s 1s/step - loss: 1.0917 - accuracy: 0.6083 - val_loss: 1.2503 - val_accuracy: 0.5333\n","Epoch 20/20\n","8/8 [==============================] - 10s 1s/step - loss: 0.9834 - accuracy: 0.6125 - val_loss: 1.2479 - val_accuracy: 0.5333\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"markdown","source":["# 모델 평가 (Evaluate Network)"],"metadata":{"id":"h_LqwepVrPC9"}},{"cell_type":"code","source":["# 모델 평가\n","validation_loss, validation_accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Loss: {validation_loss}\")\n","print(f\"Validation Accuracy: {validation_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RefHsiCqhpg","executionInfo":{"status":"ok","timestamp":1702902213445,"user_tz":-540,"elapsed":899,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"2f624675-0847-4dd7-e029-b27dfbf9e987"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 1s 223ms/step - loss: 1.2479 - accuracy: 0.5333\n","Validation Loss: 1.2478619813919067\n","Validation Accuracy: 0.5333333611488342\n"]}]},{"cell_type":"markdown","source":["# 예측 수행 (Make Predictions)\n",": 쓰레기 이미지를 넣어 쓰레기의 종류를 분류"],"metadata":{"id":"LmEQAcNfv_8N"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import os\n","\n","# 이미지를 불러오고 전처리하는 함수\n","def load_and_preprocess_image(image_path):\n","    img = image.load_img(image_path, target_size=(resize_width, resize_height))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)  # 모델의 예상 입력 형태에 맞게 차원 추가\n","    img_array /= 255.0  # 이미지 정규화\n","    return img_array\n","\n","# 테스트 이미지 폴더 경로\n","test_images_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test'\n","\n","# 테스트 이미지 파일 목록 가져오기\n","test_image_files = [os.path.join(test_images_path, f) for f in os.listdir(test_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","# 각 이미지에 대해 예측 수행\n","for image_file in test_image_files:\n","    img_array = load_and_preprocess_image(image_file)\n","    predictions = model.predict(img_array)\n","    predicted_class_index = np.argmax(predictions[0])\n","    predicted_class_name = class_names[predicted_class_index]\n","    print(f\"Image: {image_file}, Predicted class: {predicted_class_name}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCGIsKcM8rPY","executionInfo":{"status":"ok","timestamp":1702903581880,"user_tz":-540,"elapsed":3212,"user":{"displayName":"유현덕","userId":"06114095734886086625"}},"outputId":"a93b5501-3fc8-4ec2-99f3-aa324628a916"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/metal72.jpg, Predicted class: plastic\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/metal70.jpg, Predicted class: glass\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/metal71.jpg, Predicted class: plastic\n","1/1 [==============================] - 0s 21ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/cardboard38.jpg, Predicted class: cardboard\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/cardboard36.jpg, Predicted class: metal\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/cardboard37.jpg, Predicted class: plastic\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/paper644.jpg, Predicted class: paper\n","1/1 [==============================] - 0s 23ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/paper642.jpg, Predicted class: paper\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/paper643.jpg, Predicted class: trash\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/white-glass54.jpg, Predicted class: cardboard\n","1/1 [==============================] - 0s 19ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/white-glass52.jpg, Predicted class: cardboard\n","1/1 [==============================] - 0s 20ms/step\n","Image: /content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/test/white-glass53.jpg, Predicted class: cardboard\n"]}]}]}