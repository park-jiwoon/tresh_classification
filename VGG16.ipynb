{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1nTYwBcMS2Oe8A3xcZPKYTpIjZs3-u2t5","authorship_tag":"ABX9TyNdiurMZiaSjXWUBdKrGOXp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"kyC9qeLiCRsT","executionInfo":{"status":"ok","timestamp":1703139951247,"user_tz":-540,"elapsed":3,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"outputs":[],"source":["import os\n","import cv2\n","import shutil\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import models, layers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"code","source":["# 원본 데이터셋 경로\n","source_dataset_path  = '/content/drive/MyDrive/Python_project/Data/current_dataset'\n","resized_dataset_path = '/content/drive/MyDrive/Python_project/Data/resized_dataset'\n","model_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/model'\n","\n","# 쓰레기 카테고리\n","categories = ['glass','metal','paper','plastic','vinyl']\n","sizes = []\n","\n","# 이미지 리사이즈 크기 결정\n","resize_width, resize_height = 528, 532"],"metadata":{"id":"y_8QhWXzC-n4","executionInfo":{"status":"ok","timestamp":1703139959080,"user_tz":-540,"elapsed":1,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["for category in categories:\n","    category_path = os.path.join(source_dataset_path, category)\n","    image_files = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","    for filename in image_files[:]:\n","        file_path = os.path.join(category_path, filename)\n","        image = cv2.imread(file_path)\n","        if image is not None:\n","          sizes.append(image.shape[:2])"],"metadata":{"id":"kmtUNsviDWrK","executionInfo":{"status":"ok","timestamp":1703140348091,"user_tz":-540,"elapsed":379034,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 카테고리별로 폴더를 순회하며 이미지 처리\n","for category in categories:\n","    source_category_path = os.path.join(source_dataset_path, category)\n","    resized_category_path = os.path.join(resized_dataset_path, category)\n","    os.makedirs(resized_category_path, exist_ok=True)\n","\n","    # 이미지 파일 처리\n","    image_files = os.listdir(source_category_path)[:]\n","    for filename in image_files:\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            file_path = os.path.join(source_category_path, filename)\n","            image = cv2.imread(file_path)\n","            if image is not None:\n","                resized_image = cv2.resize(image, (resize_width, resize_height))\n","                cv2.imwrite(os.path.join(resized_category_path, filename), resized_image)"],"metadata":{"id":"0KX5-acrDYTJ","executionInfo":{"status":"ok","timestamp":1703140514587,"user_tz":-540,"elapsed":166499,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def scale_pixels(image):\n","    \"\"\"이미지 픽셀 값을 -1에서 1 사이의 값으로 스케일링합니다.\"\"\"\n","    return (image / 127.5) - 1\n","\n","train_datagen = ImageDataGenerator(\n","    preprocessing_function=scale_pixels,\n","    rotation_range=10,  # 회전 범위를 줄임\n","    width_shift_range=0.05,  # 이동 범위를 줄임\n","    height_shift_range=0.05,  # 이동 범위를 줄임\n","    shear_range=0.05,  # 전단 변환 범위를 줄임\n","    zoom_range=0.05,  # 확대/축소 범위를 줄임\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    validation_split=0.2\n",")\n","\n","# 참고 : https://tykimos.github.io/2017/06/10/CNN_Data_Augmentation/\n","\n","# 학습 데이터셋 로더 설정\n","train_generator = train_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=16,\n","    class_mode='categorical',\n","    subset='training'  # 학습 데이터셋\n",")\n","\n","# 검증 데이터셋 로더 설정\n","validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 검증 데이터셋도 정규화 필요\n","validation_generator = validation_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=16,\n","    class_mode='categorical',\n","    subset='validation'  # 검증 데이터셋\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYFNfB97Da4K","executionInfo":{"status":"ok","timestamp":1703140841946,"user_tz":-540,"elapsed":482,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"4bf9e417-9cd9-4459-d9d7-08170a8732fd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6644 images belonging to 5 classes.\n","Found 1659 images belonging to 5 classes.\n"]}]},{"cell_type":"code","source":["vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(resize_width, resize_height, 3))"],"metadata":{"id":"QSvRn2aCDtnA","executionInfo":{"status":"ok","timestamp":1703140844393,"user_tz":-540,"elapsed":457,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model = models.Sequential()\n","model.add(vgg_base)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dropout(0.1))\n","model.add(layers.Dense(5, activation='softmax'))  # 클래스 수에 따라 조정"],"metadata":{"id":"MZet-SH1D5ow","executionInfo":{"status":"ok","timestamp":1703140847228,"user_tz":-540,"elapsed":1,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["vgg_base.trainable = False"],"metadata":{"id":"mMB-xHmGD63v","executionInfo":{"status":"ok","timestamp":1703140850389,"user_tz":-540,"elapsed":691,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","\n","# 모델 컴파일\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"Mj9ifNCCHFqB","executionInfo":{"status":"ok","timestamp":1703140945404,"user_tz":-540,"elapsed":2,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","checkpoint_path = '/content/drive/MyDrive/Python_project/Data/model_checkpoint.h5'\n","\n","# 모델 체크포인트 콜백 생성\n","checkpoint_callback = ModelCheckpoint(\n","    checkpoint_path,\n","    monitor='val_accuracy',\n","    verbose=1,\n","    save_best_only=True,\n","    mode='max'\n",")\n","\n","# 모델 학습 코드에 콜백을 추가\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=len(train_generator),\n","    epochs=10,\n","    validation_data=validation_generator,\n","    validation_steps=len(validation_generator),\n","    callbacks=[checkpoint_callback]  # 콜백 리스트에 추가\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TKB-SfYD8Ro","outputId":"8df77ba9-9a66-4267-bac4-8f0591d43770"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","416/416 [==============================] - ETA: 0s - loss: 1.3422 - accuracy: 0.7816"]}]},{"cell_type":"code","source":["# 모델 평가\n","validation_loss, validation_accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Loss: {validation_loss}\")\n","print(f\"Validation Accuracy: {validation_accuracy}\")\n","\n","# 테스트 이미지에 대한 예측 수행\n","for image_file in test_image_files:\n","    img_array = load_and_preprocess_image(image_file)\n","    predictions = model.predict(img_array)\n","    predicted_class_index = np.argmax(predictions[0])\n","    predicted_class_name = categories[predicted_class_index]\n","    print(f\"Image: {image_file}, Predicted class: {predicted_class_name}\")"],"metadata":{"id":"HF_prtavD-lw","executionInfo":{"status":"aborted","timestamp":1703140521232,"user_tz":-540,"elapsed":4,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}}},"execution_count":null,"outputs":[]}]}