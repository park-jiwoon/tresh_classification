{"cells":[{"cell_type":"markdown","metadata":{"id":"DAltqKmWx9Ym"},"source":["세팅"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMUVvc8KgNPp","executionInfo":{"status":"ok","timestamp":1703130783778,"user_tz":-540,"elapsed":24389,"user":{"displayName":"송종현","userId":"01720111770262736086"}},"outputId":"cac5f17c-7333-4f8c-a833-662424281949"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"k_UtfSifxJHU","executionInfo":{"status":"ok","timestamp":1703130903332,"user_tz":-540,"elapsed":3836,"user":{"displayName":"송종현","userId":"01720111770262736086"}}},"outputs":[],"source":["import os\n","import cv2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","import numpy as np\n","import shutil\n","\n","# 원본 데이터셋 경로\n","source_dataset_path  = '/content/drive/MyDrive/00_05_4_daejeon_3/2023.12.26 프로젝트/data/current_dataset'\n","resized_dataset_path = '/content/drive/MyDrive/Python_project/Data/resized_dataset'\n","model_path = '/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/model'\n","\n","# 쓰레기 카테고리\n","categories = ['glass','metal','paper','plastic','vinyl']\n","sizes = []\n","\n","# 테스트를 위해 갯수 제한\n","# images_per_category = 300\n","\n","# 이미지 리사이즈 크기 결정\n","resize_width, resize_height = 384, 512"]},{"cell_type":"markdown","metadata":{"id":"AZI3sBs7yC3G"},"source":["리사이즈 이미지 설정"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9hxHto7-yBdV","executionInfo":{"status":"ok","timestamp":1703131180525,"user_tz":-540,"elapsed":274720,"user":{"displayName":"송종현","userId":"01720111770262736086"}}},"outputs":[],"source":["for category in categories:\n","    category_path = os.path.join(source_dataset_path, category)\n","    # 카테고리 폴더 내의 이미지 중 png,jpg,jpeg 필터링\n","    # 앞의 f 필터링된 파일이름\n","    # 뒤의 f 카테고리 폴더의 모든 파일\n","    # f.lower().endswith(('.png', '.jpg', '.jpeg') -> 파일이름을 소문자로 변경하고\n","    # 해당 이름이 '.png', '.jpg', 또는 '.jpeg'로 끝나는지를 검사\n","    image_files = [f for f in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","    # 각 카테고리별로 지정된 수의 이미지만 처리\n","    for filename in image_files[:]:# images_per_category\n","        file_path = os.path.join(category_path, filename)\n","        # OpenCV를 사용하여 이미지를 로드하고, 이미지의 크기를 sizes 리스트에 추가합니다.\n","        image = cv2.imread(file_path)\n","        if image is not None:\n","            sizes.append(image.shape[:2])  # 이미지의 높이와 너비만 추출"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1703131180525,"user":{"displayName":"송종현","userId":"01720111770262736086"},"user_tz":-540},"id":"cdWx-30NdcVp","outputId":"397bc585-c40c-4c8b-aa62-82d70433573f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((527.9009996386848, 532.3878116343491), (64, 64), (384, 474))"]},"metadata":{},"execution_count":5}],"source":["# 이미지 크기 통계 계산\n","if sizes:\n","    heights, widths = zip(*sizes)\n","    avg_height = sum(heights) / len(heights)\n","    avg_width = sum(widths) / len(widths)\n","    min_height = min(heights)\n","    min_width = min(widths)\n","    median_height = sorted(heights)[len(heights) // 2]\n","    median_width = sorted(widths)[len(widths) // 2]\n","else:\n","    avg_height = avg_width = min_height = min_width = median_height = median_width = 0\n","\n","(avg_height, avg_width), (min_height, min_width), (median_height, median_width)"]},{"cell_type":"markdown","metadata":{"id":"cBbrnNCNyQFu"},"source":["이미지 리사이즈"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwUm9KFgyUaV"},"outputs":[],"source":["# 카테고리별로 폴더를 순회하며 이미지 처리\n","for category in categories:\n","    source_category_path = os.path.join(source_dataset_path, category)\n","    resized_category_path = os.path.join(resized_dataset_path, category)\n","    os.makedirs(resized_category_path, exist_ok=True)  # 리사이즈된 이미지 저장 폴더 생성\n","    # exist_ok=True 해당 디렉토리에 폴더가 존재해도 오류를 발생시키지 않고 넘어감\n","\n","    # 이미지 파일 처리\n","    # images_per_category\n","    image_files = os.listdir(source_category_path)[:]  # 각 폴더별로 처음 50개의 파일만 가져옴\n","    for filename in image_files:\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            file_path = os.path.join(source_category_path, filename)\n","            image = cv2.imread(file_path)\n","            if image is not None:\n","                resized_image = cv2.resize(image, (resize_width, resize_height))\n","                cv2.imwrite(os.path.join(resized_category_path, filename), resized_image)"]},{"cell_type":"markdown","metadata":{"id":"8t-WTrnJybcW"},"source":["데이터 전처리 및 분할"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lKWGZh3zyZxu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703087411545,"user_tz":-540,"elapsed":463,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"89aa9d1a-d1f7-4d38-b6e8-ec7ed768a3a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6644 images belonging to 5 classes.\n","Found 1659 images belonging to 5 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,  # 이미지 회전 범위\n","    width_shift_range=0.1,  # 수평 이동 범위\n","    height_shift_range=0.1,  # 수직 이동 범위\n","    shear_range=0.1,  # 전단 변환 범위\n","    zoom_range=0.1,  # 확대/축소 범위\n","    horizontal_flip=True,  # 수평 뒤집기 적용\n","    fill_mode='nearest',\n","    validation_split=0.2  # 데이터셋의 20%를 검증 데이터로 사용\n",")\n","\n","# 참고 : https://tykimos.github.io/2017/06/10/CNN_Data_Augmentation/\n","\n","# 학습 데이터셋 로더 설정\n","train_generator = train_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=64,\n","    class_mode='categorical',\n","    subset='training'  # 학습 데이터셋\n",")\n","\n","# 검증 데이터셋 로더 설정\n","validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 검증 데이터셋도 정규화 필요\n","validation_generator = validation_datagen.flow_from_directory(\n","    resized_dataset_path,\n","    target_size=(resize_width, resize_height),\n","    batch_size=64,\n","    class_mode='categorical',\n","    subset='validation'  # 검증 데이터셋\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hsaJUOzdjjZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703087411546,"user_tz":-540,"elapsed":4,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"cb950f80-f7d0-458a-eb04-3004a30db4cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["104"]},"metadata":{},"execution_count":6}],"source":["len(train_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRg4RmX3dkoh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703087411546,"user_tz":-540,"elapsed":3,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"173be131-a376-4352-d3f8-2c0883ffd5f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{},"execution_count":7}],"source":["len(validation_generator)"]},{"cell_type":"markdown","metadata":{"id":"Hq5PaMWhyhOu"},"source":["모델 정의 (Define Network)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NLpry-1yjJP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703088116598,"user_tz":-540,"elapsed":292,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"88f7711d-858e-4060-abec-99989a69a2ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 380, 508, 32)      2432      \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 190, 254, 32)      0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 186, 250, 64)      51264     \n","                                                                 \n"," max_pooling2d_5 (MaxPoolin  (None, 93, 125, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 89, 121, 128)      204928    \n","                                                                 \n"," max_pooling2d_6 (MaxPoolin  (None, 44, 60, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 40, 56, 128)       409728    \n","                                                                 \n"," max_pooling2d_7 (MaxPoolin  (None, 20, 28, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 20, 28, 128)       0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 71680)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               9175168   \n","                                                                 \n"," dense_3 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 9844165 (37.55 MB)\n","Trainable params: 9844165 (37.55 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# 모델 구축\n","model = Sequential([\n","    Conv2D(32, (5, 5), activation='relu', input_shape=(resize_width, resize_height, 3)),\n","    MaxPooling2D(2, 2),\n","    Conv2D(64, (5, 5), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (5, 5), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (5, 5), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Dropout(0.5),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(5, activation='softmax')\n","])\n","\n","\n","# 모델 요약\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"oCc6s9LlylRW"},"source":["모델 컴파일 (Compile Network)\n","keras코드 -> tensorflow 코드로 변환"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-Hy-NroynUO"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n","# 모델 컴파일\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"markdown","metadata":{"id":"wbMXEZI9y94W"},"source":["모델 학습 (Fit Network)"]},{"cell_type":"code","source":["# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=len(train_generator),  # 학습 데이터셋의 이미지 수를 배치 크기로 나눈 값\n","    epochs=50,\n","    validation_data=validation_generator,\n","    validation_steps=len(validation_generator)  # 검증 데이터셋의 이미지 수를 배치 크기로 나눈 값\n",")\n","# 수업 때 배운 걸로 모델 저장하면서 학습\n","model_save_path = os.path.join(model_path, 'my_model.h5')\n","model.save(model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZf5yXvwvCMZ","executionInfo":{"status":"ok","timestamp":1703103898321,"user_tz":-540,"elapsed":15668821,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"f24565cc-7b9a-4747-aa3f-6ae863d269fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","104/104 [==============================] - 314s 3s/step - loss: 1.4833 - accuracy: 0.3432 - val_loss: 1.4092 - val_accuracy: 0.3550\n","Epoch 2/50\n","104/104 [==============================] - 294s 3s/step - loss: 1.2754 - accuracy: 0.4664 - val_loss: 1.2154 - val_accuracy: 0.4985\n","Epoch 3/50\n","104/104 [==============================] - 291s 3s/step - loss: 1.1192 - accuracy: 0.5601 - val_loss: 1.3038 - val_accuracy: 0.4575\n","Epoch 4/50\n","104/104 [==============================] - 290s 3s/step - loss: 1.0163 - accuracy: 0.6031 - val_loss: 1.1488 - val_accuracy: 0.5491\n","Epoch 5/50\n","104/104 [==============================] - 293s 3s/step - loss: 0.9174 - accuracy: 0.6493 - val_loss: 1.1807 - val_accuracy: 0.5353\n","Epoch 6/50\n","104/104 [==============================] - 295s 3s/step - loss: 0.8504 - accuracy: 0.6743 - val_loss: 1.1057 - val_accuracy: 0.5708\n","Epoch 7/50\n","104/104 [==============================] - 295s 3s/step - loss: 0.8172 - accuracy: 0.6908 - val_loss: 1.0276 - val_accuracy: 0.6160\n","Epoch 8/50\n","104/104 [==============================] - 292s 3s/step - loss: 0.7309 - accuracy: 0.7336 - val_loss: 0.9887 - val_accuracy: 0.6323\n","Epoch 9/50\n","104/104 [==============================] - 292s 3s/step - loss: 0.6614 - accuracy: 0.7580 - val_loss: 0.9809 - val_accuracy: 0.6468\n","Epoch 10/50\n","104/104 [==============================] - 291s 3s/step - loss: 0.6411 - accuracy: 0.7721 - val_loss: 1.0584 - val_accuracy: 0.6221\n","Epoch 11/50\n","104/104 [==============================] - 298s 3s/step - loss: 0.5953 - accuracy: 0.7836 - val_loss: 0.9533 - val_accuracy: 0.6383\n","Epoch 12/50\n","104/104 [==============================] - 292s 3s/step - loss: 0.5873 - accuracy: 0.7876 - val_loss: 0.9398 - val_accuracy: 0.6661\n","Epoch 13/50\n","104/104 [==============================] - 289s 3s/step - loss: 0.5420 - accuracy: 0.8010 - val_loss: 0.9208 - val_accuracy: 0.6661\n","Epoch 14/50\n","104/104 [==============================] - 291s 3s/step - loss: 0.5242 - accuracy: 0.8143 - val_loss: 0.8779 - val_accuracy: 0.6992\n","Epoch 15/50\n","104/104 [==============================] - 288s 3s/step - loss: 0.5229 - accuracy: 0.8110 - val_loss: 0.8473 - val_accuracy: 0.6878\n","Epoch 16/50\n","104/104 [==============================] - 289s 3s/step - loss: 0.4774 - accuracy: 0.8296 - val_loss: 0.8852 - val_accuracy: 0.6908\n","Epoch 17/50\n","104/104 [==============================] - 293s 3s/step - loss: 0.4574 - accuracy: 0.8340 - val_loss: 0.8322 - val_accuracy: 0.7022\n","Epoch 18/50\n","104/104 [==============================] - 314s 3s/step - loss: 0.4426 - accuracy: 0.8436 - val_loss: 0.9168 - val_accuracy: 0.6811\n","Epoch 19/50\n","104/104 [==============================] - 312s 3s/step - loss: 0.4273 - accuracy: 0.8513 - val_loss: 0.9519 - val_accuracy: 0.6817\n","Epoch 20/50\n","104/104 [==============================] - 323s 3s/step - loss: 0.4096 - accuracy: 0.8517 - val_loss: 0.8498 - val_accuracy: 0.7149\n","Epoch 21/50\n","104/104 [==============================] - 319s 3s/step - loss: 0.3817 - accuracy: 0.8650 - val_loss: 1.0352 - val_accuracy: 0.6872\n","Epoch 22/50\n","104/104 [==============================] - 317s 3s/step - loss: 0.3882 - accuracy: 0.8654 - val_loss: 0.9100 - val_accuracy: 0.7034\n","Epoch 23/50\n","104/104 [==============================] - 330s 3s/step - loss: 0.3488 - accuracy: 0.8808 - val_loss: 0.9723 - val_accuracy: 0.7022\n","Epoch 24/50\n","104/104 [==============================] - 321s 3s/step - loss: 0.3454 - accuracy: 0.8764 - val_loss: 0.8870 - val_accuracy: 0.7064\n","Epoch 25/50\n","104/104 [==============================] - 326s 3s/step - loss: 0.3390 - accuracy: 0.8778 - val_loss: 0.8742 - val_accuracy: 0.7245\n","Epoch 26/50\n","104/104 [==============================] - 322s 3s/step - loss: 0.3437 - accuracy: 0.8808 - val_loss: 0.8846 - val_accuracy: 0.7360\n","Epoch 27/50\n","104/104 [==============================] - 324s 3s/step - loss: 0.3393 - accuracy: 0.8835 - val_loss: 0.9113 - val_accuracy: 0.7077\n","Epoch 28/50\n","104/104 [==============================] - 324s 3s/step - loss: 0.3238 - accuracy: 0.8829 - val_loss: 0.8935 - val_accuracy: 0.7203\n","Epoch 29/50\n","104/104 [==============================] - 323s 3s/step - loss: 0.3107 - accuracy: 0.8913 - val_loss: 0.9804 - val_accuracy: 0.7101\n","Epoch 30/50\n","104/104 [==============================] - 333s 3s/step - loss: 0.3172 - accuracy: 0.8885 - val_loss: 0.9009 - val_accuracy: 0.7149\n","Epoch 31/50\n","104/104 [==============================] - 331s 3s/step - loss: 0.2865 - accuracy: 0.9005 - val_loss: 0.8561 - val_accuracy: 0.7360\n","Epoch 32/50\n","104/104 [==============================] - 328s 3s/step - loss: 0.2688 - accuracy: 0.9100 - val_loss: 1.0000 - val_accuracy: 0.7137\n","Epoch 33/50\n","104/104 [==============================] - 325s 3s/step - loss: 0.3079 - accuracy: 0.8886 - val_loss: 0.9065 - val_accuracy: 0.7390\n","Epoch 34/50\n","104/104 [==============================] - 326s 3s/step - loss: 0.2673 - accuracy: 0.9055 - val_loss: 0.9791 - val_accuracy: 0.6950\n","Epoch 35/50\n","104/104 [==============================] - 324s 3s/step - loss: 0.2731 - accuracy: 0.9022 - val_loss: 0.9126 - val_accuracy: 0.7366\n","Epoch 36/50\n","104/104 [==============================] - 323s 3s/step - loss: 0.2463 - accuracy: 0.9136 - val_loss: 0.9430 - val_accuracy: 0.7414\n","Epoch 37/50\n","104/104 [==============================] - 324s 3s/step - loss: 0.2704 - accuracy: 0.9061 - val_loss: 0.9620 - val_accuracy: 0.7034\n","Epoch 38/50\n","104/104 [==============================] - 329s 3s/step - loss: 0.2399 - accuracy: 0.9169 - val_loss: 0.8153 - val_accuracy: 0.7613\n","Epoch 39/50\n","104/104 [==============================] - 327s 3s/step - loss: 0.2500 - accuracy: 0.9145 - val_loss: 0.9372 - val_accuracy: 0.7306\n","Epoch 40/50\n","104/104 [==============================] - 323s 3s/step - loss: 0.2654 - accuracy: 0.9056 - val_loss: 0.9030 - val_accuracy: 0.7456\n","Epoch 41/50\n","104/104 [==============================] - 322s 3s/step - loss: 0.2427 - accuracy: 0.9109 - val_loss: 0.8359 - val_accuracy: 0.7444\n","Epoch 42/50\n","104/104 [==============================] - 321s 3s/step - loss: 0.2291 - accuracy: 0.9196 - val_loss: 1.0790 - val_accuracy: 0.7300\n","Epoch 43/50\n","104/104 [==============================] - 321s 3s/step - loss: 0.2217 - accuracy: 0.9213 - val_loss: 0.9323 - val_accuracy: 0.7324\n","Epoch 44/50\n","104/104 [==============================] - 319s 3s/step - loss: 0.2266 - accuracy: 0.9234 - val_loss: 0.9049 - val_accuracy: 0.7505\n","Epoch 45/50\n","104/104 [==============================] - 323s 3s/step - loss: 0.2326 - accuracy: 0.9226 - val_loss: 0.8586 - val_accuracy: 0.7480\n","Epoch 46/50\n","104/104 [==============================] - 323s 3s/step - loss: 0.2398 - accuracy: 0.9195 - val_loss: 0.8563 - val_accuracy: 0.7589\n","Epoch 47/50\n","104/104 [==============================] - 328s 3s/step - loss: 0.2339 - accuracy: 0.9202 - val_loss: 0.8750 - val_accuracy: 0.7408\n","Epoch 48/50\n","104/104 [==============================] - 325s 3s/step - loss: 0.2241 - accuracy: 0.9223 - val_loss: 1.0525 - val_accuracy: 0.7294\n","Epoch 49/50\n","104/104 [==============================] - 326s 3s/step - loss: 0.2137 - accuracy: 0.9261 - val_loss: 0.9097 - val_accuracy: 0.7396\n","Epoch 50/50\n","104/104 [==============================] - 322s 3s/step - loss: 0.2071 - accuracy: 0.9256 - val_loss: 1.0963 - val_accuracy: 0.7179\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","# 모델을 로드합니다.\n","model = load_model(\"/content/drive/MyDrive/딥러닝프로젝트_쓰레기분류모델_CNN/data/model/my_model.h5\")"],"metadata":{"id":"PmMWbOvZtSFt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"36RJ2UHGzEwW"},"source":["모델 평가 (Evaluate Network)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"jtOH-zQbzGsl","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"error","timestamp":1703130752905,"user_tz":-540,"elapsed":6,"user":{"displayName":"송종현","userId":"01720111770262736086"}},"outputId":"839e16f8-ca84-401e-874d-d2dba9ee85db"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6d13362997a0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Loss: {validation_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Accuracy: {validation_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["# 모델 평가\n","validation_loss, validation_accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Loss: {validation_loss}\")\n","print(f\"Validation Accuracy: {validation_accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"nwKXmm4OzMd-"},"source":["예측 수행 (Make Predictions): 쓰레기 이미지를 넣어 쓰레기의 종류를 분류"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KTO49i2qzNx2","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"error","timestamp":1703119168458,"user_tz":-540,"elapsed":1359,"user":{"displayName":"곽한빈","userId":"12753390330832787926"}},"outputId":"c798a347-f17b-4641-fa07-6a4132be1774"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-fc1742291e90>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 각 이미지에 대해 예측 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_image_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpredicted_class_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-fc1742291e90>\u001b[0m in \u001b[0;36mload_and_preprocess_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 이미지를 불러오고 전처리하는 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_preprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 모델의 예상 입력 형태에 맞게 차원 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'resize_width' is not defined"]}],"source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import os\n","\n","# 이미지를 불러오고 전처리하는 함수\n","def load_and_preprocess_image(image_path):\n","    img = image.load_img(image_path, target_size=(resize_width, resize_height))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)  # 모델의 예상 입력 형태에 맞게 차원 추가\n","    img_array /= 255.0  # 이미지 정규화\n","    return img_array\n","\n","# 테스트 이미지 폴더 경로\n","test_images_path = '/content/drive/MyDrive/Python_project/Data/img'\n","\n","# 테스트 이미지 파일 목록 가져오기\n","test_image_files = [os.path.join(test_images_path, f) for f in os.listdir(test_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","# 각 이미지에 대해 예측 수행\n","for image_file in test_image_files:\n","    img_array = load_and_preprocess_image(image_file)\n","    predictions = model.predict(img_array)\n","    predicted_class_index = np.argmax(predictions[0])\n","    predicted_class_name = categories[predicted_class_index]\n","    print(f\"Image: {image_file}, Predicted class: {predicted_class_name}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgDwQbJ3xP5A"},"outputs":[],"source":["import os\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 이미지를 불러오고 전처리하는 함수\n","def load_and_preprocess_image(image_path):\n","    img = image.load_img(image_path, target_size=(resize_width, resize_height))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)  # 모델의 예상 입력 형태에 맞게 차원 추가\n","    img_array /= 255.0  # 이미지 정규화\n","    return img_array\n","\n","# 디렉토리 이름에서 레이블 추출\n","def extract_label_from_directory(file_path):\n","    return os.path.basename(os.path.dirname(file_path))\n","\n","# 테스트 이미지 폴더 경로\n","test_images_path = '/content/drive/MyDrive/Python_project/Data/img'\n","\n","# 테스트 이미지 파일 목록 가져오기\n","test_image_files = [os.path.join(test_images_path, f) for f in os.listdir(test_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","# 각 이미지에 대해 예측 수행 및 시각화\n","for image_file in test_image_files:\n","    true_label = extract_label_from_directory(image_file)\n","    img_array = load_and_preprocess_image(image_file)\n","    predictions = model.predict(img_array)\n","    predicted_class_index = np.argmax(predictions[0])\n","    predicted_class_name = categories[predicted_class_index]\n","\n","    # 시각화\n","    img = plt.imread(image_file)\n","    plt.imshow(img)\n","    plt.title(f\"Predicted: {predicted_class_name}\")\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWHhfdJsyQxo"},"outputs":[],"source":["import os\n","import re\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# 이미지를 불러오고 전처리하는 함수\n","def load_and_preprocess_image(img_path):\n","    img = image.load_img(img_path, target_size=(resize_width, resize_height))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0) / 255.0\n","    return img_array\n","\n","# 파일 이름에서 레이블 추출\n","def get_label_from_filename(file_name):\n","    if re.match(r'glass\\d+', file_name):\n","        return 'glass'\n","    elif re.match(r'metal\\d+', file_name):\n","        return 'metal'\n","    elif re.match(r'paper\\d+', file_name):\n","        return 'paper'\n","    elif re.match(r'plastic\\d+', file_name):\n","        return 'plastic'\n","    elif re.match(r'\\d+', file_name):  # 숫자로만 이루어진 파일 이름 처리\n","        return 'vinyl'\n","    elif re.match(r'trach\\d+', file_name):  # 'trach'로 시작하는 파일 이름 처리\n","        return 'vinyl'\n","    else:\n","        return 'unknown'  # 알려지지 않은 패턴 처리\n","\n","# 모델 예측 및 정확도 계산\n","def evaluate_model_accuracy(model, base_path, categories):\n","    correct_predictions = 0\n","    total_images = 0\n","\n","    # base_path 폴더 내의 모든 파일을 검색\n","    for file_name in os.listdir(base_path):\n","        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            # 레이블 추출 및 이미지 전처리\n","            true_label = get_label_from_filename(file_name)\n","            if true_label != 'unknown':  # 알 수 없는 레이블을 제외\n","                img_path = os.path.join(base_path, file_name)\n","                img_array = load_and_preprocess_image(img_path)\n","\n","                # 예측 실행\n","                prediction = model.predict(img_array)\n","                predicted_label_index = np.argmax(prediction[0])\n","                predicted_label = categories[predicted_label_index]\n","\n","                # 예측 및 실제 레이블 출력\n","                print(f\"Actual: {true_label}, Predicted: {predicted_label}\")\n","\n","                # 예측 정확도 업데이트\n","                if predicted_label == true_label:\n","                    correct_predictions += 1\n","                total_images += 1\n","\n","    # 정확도 계산 및 출력\n","    accuracy = correct_predictions / total_images if total_images > 0 else 0\n","    return accuracy\n","\n","# 모델 정확도 평가\n","base_path = '/content/drive/MyDrive/Python_project/Data/img'\n","categories = ['glass', 'metal', 'paper', 'plastic', 'vinyl']  # 모델이 예측하는 클래스 목록\n","accuracy = evaluate_model_accuracy(model, base_path, categories)\n","print(\"\\n\")\n","print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}